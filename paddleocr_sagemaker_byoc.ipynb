{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying PaddleOCR in SageMaker Studio\n",
    "\n",
    "(Optional) Update SageMaker to the latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional to run the below\n",
    "\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install -q --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The **SageMaker Python SDK** helps you deploy your models for training and hosting in optimized, productions ready containers in SageMaker. The SageMaker Python SDK is easy to use, modular, extensible and compatible with TensorFlow, MXNet, PyTorch and Chainer. This tutorial focuses on how to deploy a PaddleOCR model to capture the text values of captured license plate images.\n",
    "\n",
    "### Set up the environment\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the sagemaker.get_execution_role() with appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.session import Session\n",
    "\n",
    "session = Session()\n",
    "region = session.boto_region_name\n",
    "bucket = session.default_bucket()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose Dockerfile for the base image used for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM registry.baidubce.com/paddlepaddle/paddle:2.1.0 as build\n",
    "# To use GPU mode, use below base image instead\n",
    "# FROM nvidia/cuda:10.2-cudnn7-devel-ubuntu16.04\n",
    "    \n",
    "# Set a docker label to advertise multi-model support on the container\n",
    "LABEL com.amazonaws.sagemaker.capabilities.multi-models=true\n",
    "# Set a docker label to enable container to use SAGEMAKER_BIND_TO_PORT environment variable if present\n",
    "LABEL com.amazonaws.sagemaker.capabilities.accept-bind-to-port=true\n",
    "\n",
    "ARG PYTHON_VERSION=3.7.10\n",
    "ARG MMS_VERSION=1.0.8\n",
    "\n",
    "# See http://bugs.python.org/issue19846\n",
    "ENV LANG C.UTF-8\n",
    "ENV LD_LIBRARY_PATH /opt/conda/lib/:$LD_LIBRARY_PATH\n",
    "ENV PATH /opt/conda/bin:$PATH\n",
    "\n",
    "\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
    "    build-essential \\\n",
    "    ca-certificates \\\n",
    "    cmake \\\n",
    "    curl \\\n",
    "    git \\\n",
    "    jq \\\n",
    "    libgl1-mesa-glx \\\n",
    "    libglib2.0-0 \\\n",
    "    libsm6 \\\n",
    "    libxext6 \\\n",
    "    libxrender-dev \\\n",
    "    openjdk-8-jdk-headless \\\n",
    "    vim \\\n",
    "    wget \\\n",
    "    zlib1g-dev\n",
    "\n",
    "RUN curl -L -o ~/miniconda.sh https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh \\\n",
    " && chmod +x ~/miniconda.sh \\\n",
    " && ~/miniconda.sh -b -p /opt/conda \\\n",
    " && rm ~/miniconda.sh \\\n",
    " && /opt/conda/bin/conda update conda \\\n",
    " && /opt/conda/bin/conda install -y \\\n",
    "    python=$PYTHON_VERSION \\\n",
    "    cython==0.29.12 \\\n",
    "    ipython==7.7.0 \\\n",
    "    mkl-include==2019.4 \\\n",
    "    mkl==2019.4 \\\n",
    "    numpy==1.16.4 \\\n",
    "    scipy==1.3.0 \\\n",
    "    typing==3.6.4 \\\n",
    " && /opt/conda/bin/conda clean -ya\n",
    "\n",
    "# install paddleocr\n",
    "RUN pip3 install paddlepaddle # Change to \"RUN pip3 install paddlepaddle-gpu==2.0.2\" for using GPU\n",
    "RUN pip3 install \"paddleocr>=2.0.1\" \n",
    "\n",
    "# Install MXNet, MMS, and SageMaker Inference Toolkit to set up MMS\n",
    "RUN pip3 --no-cache-dir install mxnet \\\n",
    "                                multi-model-server \\\n",
    "                                sagemaker-inference \\\n",
    "                                retrying\n",
    "\n",
    "# Copy entrypoint script to the image\n",
    "COPY dockerd-entrypoint.py /usr/local/bin/dockerd-entrypoint.py\n",
    "RUN chmod +x /usr/local/bin/dockerd-entrypoint.py\n",
    "\n",
    "RUN mkdir -p /home/model-server/\n",
    "\n",
    "# Copy the default custom service file to handle incoming data and inference requests\n",
    "COPY model_handler.py /home/model-server/model_handler.py\n",
    "\n",
    "# Define an entrypoint script for the docker image\n",
    "ENTRYPOINT [\"python\", \"/usr/local/bin/dockerd-entrypoint.py\"]\n",
    "\n",
    "# Define command to be passed to the entrypoint\n",
    "CMD [\"serve\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose .py files for inference entry point and model handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile dockerd-entrypoint.py\n",
    "import subprocess\n",
    "import sys\n",
    "import shlex\n",
    "import os\n",
    "from retrying import retry\n",
    "from subprocess import CalledProcessError\n",
    "from sagemaker_inference import model_server\n",
    "\n",
    "def _retry_if_error(exception):\n",
    "    return isinstance(exception, CalledProcessError or OSError)\n",
    "\n",
    "@retry(stop_max_delay=1000 * 50,\n",
    "       retry_on_exception=_retry_if_error)\n",
    "def _start_mms():\n",
    "    # by default the number of workers per model is 1, but we can configure it through the\n",
    "    # environment variable below if desired.\n",
    "    # os.environ['SAGEMAKER_MODEL_SERVER_WORKERS'] = '2'\n",
    "    model_server.start_model_server(handler_service='/home/model-server/model_handler.py:handle')\n",
    "\n",
    "def main():\n",
    "    if sys.argv[1] == 'serve':\n",
    "        _start_mms()\n",
    "    else:\n",
    "        subprocess.check_call(shlex.split(' '.join(sys.argv[1:])))\n",
    "\n",
    "    # prevent docker exit\n",
    "    subprocess.call(['tail', '-f', '/dev/null'])\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model_handler.py\n",
    "\"\"\"\n",
    "ModelHandler defines an example model handler for load and inference requests for MXNet CPU models\n",
    "\"\"\"\n",
    "from collections import namedtuple\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from paddleocr import PaddleOCR, draw_ocr\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import base64\n",
    "\n",
    "class ModelHandler(object):\n",
    "    \"\"\"\n",
    "    A sample Model handler implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.initialized = False\n",
    "        self.ocr = None\n",
    "\n",
    "    def initialize(self, context):\n",
    "        \"\"\"\n",
    "        Initialize model. This will be called during model loading time\n",
    "        :param context: Initial context contains model server system properties.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.initialized = True\n",
    "        model_dir = \"/opt/ml/model/\"\n",
    "        \n",
    "        # Load ocr model, change \"use_gpu=False\" to \"use_gpu=True\" in case of using GPU\n",
    "        try:\n",
    "            self.ocr = PaddleOCR(det_model_dir=os.path.join(model_dir,'model/det'),\n",
    "            rec_model_dir=os.path.join(model_dir,'model/rec'),\n",
    "            cls_model_dir=os.path.join(model_dir,'model/cls'), \n",
    "            use_angle_cls=True, lang=\"ch\", use_gpu=False)\n",
    "              \n",
    "        except Exception as e:\n",
    "            raise\n",
    "            \n",
    "    def preprocess(self, request):\n",
    "        \"\"\"\n",
    "        Transform raw input into model input data.\n",
    "        :param request: list of raw requests\n",
    "        :return: list of preprocessed model input data\n",
    "        \"\"\"\n",
    "        # Take the input data and pre-process it make it inference ready\n",
    "\n",
    "        img_list = []\n",
    "        for idx, data in enumerate(request):\n",
    "            # Read the bytearray of the image from the input\n",
    "            img_arr = data.get('body')\n",
    "            img_arr = base64.b64decode(img_arr)\n",
    "            img_arr = Image.open(BytesIO(img_arr))\n",
    "            img_arr = np.array(img_arr)\n",
    "            \n",
    "            # Check the number of dimension\n",
    "            assert len(img_arr.shape) == 3, \"Dimension must be 3, but {}\".format(len(img_arr.shape)) \n",
    "\n",
    "            img_list.append(img_arr)\n",
    "\n",
    "        return img_list\n",
    "\n",
    "    def inference(self, model_input):\n",
    "        \"\"\"\n",
    "        Internal inference methods\n",
    "        :param model_input: transformed model input data list\n",
    "        :return: list of inference output \n",
    "        \"\"\"\n",
    "        res_list = []\n",
    "        # Do some inference call to engine here and return output\n",
    "        for img in model_input:\n",
    "            result = self.ocr.ocr(img, cls=True)\n",
    "            for res in result:\n",
    "                ## because float32 is not json serializable, score is converted to float (float64)\n",
    "                ## However the score is in tuple and cannot be replaced. The entire tupple is replaced as list.\n",
    "                string = res[1][0]\n",
    "                score = float(res[1][1])\n",
    "                res[1] = [string,score]\n",
    "\n",
    "            res_list.append(result)\n",
    "        return res_list\n",
    "        \n",
    "    def handle(self, data, context):\n",
    "        \"\"\"\n",
    "        Call preprocess, inference and post-process functions\n",
    "        :param data: input data\n",
    "        :param context: mms context\n",
    "        \"\"\"\n",
    "        \n",
    "        model_input = self.preprocess(data)\n",
    "        model_out = self.inference(model_input)\n",
    "        return model_out\n",
    "\n",
    "_service = ModelHandler()\n",
    "\n",
    "\n",
    "def handle(data, context):\n",
    "    if not _service.initialized:\n",
    "        _service.initialize(context)\n",
    "\n",
    "    if data is None:\n",
    "        return None\n",
    "\n",
    "    return _service.handle(data, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install libraries for building container images in SageMaker Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker-studio-image-build "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build container image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sm-docker build . --repository paddleocr-on-sagemaker-example:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the uri of the container image built and pushed to Amazon ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name \n",
    "image_uri = str(account_id) + \".dkr.ecr.\" +  region + \".amazonaws.com/paddleocr-on-sagemaker-example:latest\"\n",
    "\n",
    "print(image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the inference models from [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p model/det\n",
    "!mkdir -p model/rec\n",
    "!mkdir -p model/cls\n",
    "\n",
    "# Detection\n",
    "!wget https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_det_infer.tar -O model/det/ch_ppocr_mobile_v2.0_det_infer.tar\n",
    "!cd model/det/ && tar xvf ch_ppocr_mobile_v2.0_det_infer.tar --strip-components 1 && rm ch_ppocr_mobile_v2.0_det_infer.tar\n",
    "\n",
    "# Recognition\n",
    "!wget https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_rec_infer.tar -O model/rec/ch_ppocr_mobile_v2.0_rec_infer.tar\n",
    "!cd model/rec/ && tar xvf ch_ppocr_mobile_v2.0_rec_infer.tar --strip-components 1 && rm ch_ppocr_mobile_v2.0_rec_infer.tar\n",
    "\n",
    "# Directoin Classificatoin\n",
    "!wget https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar -O model/cls/ch_ppocr_mobile_v2.0_cls_infer.tar\n",
    "!cd model/cls/ && tar xvf ch_ppocr_mobile_v2.0_cls_infer.tar --strip-components 1 && rm ch_ppocr_mobile_v2.0_cls_infer.tar\n",
    "\n",
    "!tar -zcvf model.tar.gz model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the packed model artifact to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker \n",
    "\n",
    "model_uri = sagemaker.Session().upload_data(\"model.tar.gz\", key_prefix=\"ocr_model\")\n",
    "model_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model with inputs from the built container image and packed model artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "ocr_model = sagemaker.model.Model(image_uri,\n",
    "                      model_data=model_uri, \n",
    "                      predictor_cls=Predictor,\n",
    "                      role=sagemaker.get_execution_role())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may change the instance type to a smaller or larger one based on your performance requirement and cost considerations\n",
    "predictor = ocr_model.deploy(initial_instance_count=1,instance_type=\"ml.c5.4xlarge\")\n",
    "\n",
    "# Get the endpoint name of the deployed model\n",
    "print(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import base64\n",
    "import io\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "directory = ''\n",
    "file = 'your-file-name'\n",
    "file_path = directory + file \n",
    "with open(file_path, 'rb') as image:\n",
    "    stream = io.BytesIO(image.read())\n",
    "    image = Image.open(stream)\n",
    "\n",
    "buffered = BytesIO()\n",
    "image.save(buffered, format=\"JPEG\")\n",
    "img_str = base64.b64encode(buffered.getvalue())\n",
    "\n",
    "import json\n",
    "response = json.loads(predictor.predict(img_str))\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install glib -y\n",
    "!pip install albumentations\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "x_offset = 20\n",
    "y_offset = 0\n",
    "for i, res in enumerate(response):\n",
    "    box = np.reshape(np.array(res[0]), [-1, 1, 2]).astype(np.int64)\n",
    "    image = cv2.putText(np.array(image), '('+str(i)+')', (box[0][0][0] -x_offset, box[0][0][1]-y_offset), \n",
    "                        cv2.FONT_HERSHEY_PLAIN, 1, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    image = cv2.polylines(np.array(image), [box], True, (255, 0, 0), 2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "for i,res in enumerate(response):\n",
    "    print('('+str(i)+'): '+res[1][0], end=', ')\n",
    "fig = plt.figure(dpi=200)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional cleanup\n",
    "When you're done with the endpoint, you should clean it up.\n",
    "\n",
    "All of the training jobs, models and endpoints we created can be viewed through the SageMaker console of your AWS account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-east-1:493642496378:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
